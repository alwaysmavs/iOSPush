## 录屏推流

`PLStreamingKit` 支持 iOS 10 新增的录屏推流 ([`ReplayKit Live`](https://developer.apple.com/reference/replaykit)) 功能，开发者可通过构建 [App Extension](https://developer.apple.com/app-extensions) 来调用推流 API 实现实时游戏直播等功能。需要注意的是，实时直播需要游戏或 App 本身实现对 `ReplayKit` 的支持。

### 1. 创建 Broadcast Upload Extension

在原有直播 App 中添加一个类型为 `Broadcast Upload Extension` 的新 Target，如图所示：

![](https://raw.githubusercontent.com/pili-engineering/PLStreamingKit/master/screensnap/broadcast-extension-create.png)

Xcode 会额外自动创建一个类型为 `Broadcast UI Extension` 的 Target，用于显示调用 `Broadcast Upload Extension` 的用户界面。

### 2. 添加推流管理类

创建推流 API 调用管理类，添加头文件引用：

``` Objective-C
#import <PLMediaStreamingKit/PLStreamingKit.h>
```

头文件参考

``` Objective-C
#import <Foundation/Foundation.h>

#import <PLMediaStreamingKit/PLStreamingKit.h>

@interface BroadcastManager : NSObject

@property (nonatomic, strong) PLStreamingSession *session;

+ (instancetype)sharedBroadcastManager;
- (PLStreamState)streamState;
- (void)pushVideoSampleBuffer:(CMSampleBufferRef)sampleBuffer;
- (void)pushAudioSampleBuffer:(CMSampleBufferRef)sampleBuffer withChannelID:(const NSString *)channelID;

@end
```
类实现参考

``` Objective-C
@interface BroadcastManager ()<PLStreamingSessionDelegate>

@end

@implementation BroadcastManager

static BroadcastManager *_instance;

- (instancetype)init
{
    if (self = [super init]) {
        [PLStreamingEnv initEnv];

        PLVideoStreamingConfiguration *videoConfiguration = [[PLVideoStreamingConfiguration alloc] initWithVideoSize:CGSizeMake(1280, 720) expectedSourceVideoFrameRate:24 videoMaxKeyframeInterval:24*3 averageVideoBitRate:1000*1024 videoProfileLevel:AVVideoProfileLevelH264High41];
        PLAudioStreamingConfiguration *audioConfiguration = [PLAudioStreamingConfiguration defaultConfiguration];
        audioConfiguration.inputAudioChannelDescriptions = @[kPLAudioChannelApp, kPLAudioChannelMic];

        self.session = [[PLStreamingSession alloc] initWithVideoStreamingConfiguration:videoConfiguration
                                                           audioStreamingConfiguration:audioConfiguration
                                                                                stream:nil];
        self.session.delegate = self;
        #warning 以下 pushURL 需替换为一个真实的流地址
        NSString *pushURL = nil;
        dispatch_after(dispatch_time(DISPATCH_TIME_NOW, (int64_t)(0.5 * NSEC_PER_SEC)), dispatch_get_main_queue(), ^{
            [self.session startWithPushURL:[NSURL URLWithString:pushURL] feedback:^(PLStreamStartStateFeedback feedback) {
                if (PLStreamStartStateSuccess == feedback) {
                    NSLog(@"connect success");
                } else {
                    NSLog(@"connect failed");
                }
            }];
        });
    }
    return self;
}

+ (void)initialize
{
    _instance = [[BroadcastManager alloc] init];
}

- (PLStreamState)streamState
{
    return self.session.streamState;
}

- (void)pushVideoSampleBuffer:(CMSampleBufferRef)sampleBuffer
{
    [self.session pushVideoSampleBuffer:sampleBuffer];
}

- (void)pushAudioSampleBuffer:(CMSampleBufferRef)sampleBuffer withChannelID:(const NSString *)channelID
{
    [self.session pushAudioSampleBuffer:sampleBuffer withChannelID:channelID completion:nil];
}

+ (instancetype)sharedBroadcastManager
{
    return _instance;
}

// 实现其他必要的协议方法

- (void)streamingSession:(PLStreamingSession *)session didDisconnectWithError:(NSError *)error
{
    NSLog(@"error : %@", error);
}

- (void)streamingSession:(PLStreamingSession *)session streamStatusDidUpdate:(PLStreamStatus *)status
{
    NSLog(@"%@", status);
}

@end

```

注意 `PLAudioStreamingConfiguration` 实例生成时必需注册音频流来源

``` Objective-C
audioConfiguration.inputAudioChannelDescriptions = @[kPLAudioChannelApp, kPLAudioChannelMic];
```

其中 `kPLAudioChannelApp` 对应于 `RPSampleBufferTypeAudioApp`，是 ReplayKit Live 回调的 app 音频数据，`kPLAudioChannelMic` 对应于 `RPSampleBufferTypeAudioMic`，是 ReplayKit Live 回调的 mic 音频数据。之所以需要显示声明，是为了在 PLStreamingKit 在音频编码前将两路音频流进行混音。

在自动生成的 `SampleHandler.m` 中实现 `RPBroadcastSampleHandler` 协议部分方法如下：

``` Objective-C
- (void)processSampleBuffer:(CMSampleBufferRef)sampleBuffer withType:(RPSampleBufferType)sampleBufferType {
    if ([BroadcastManager sharedBroadcastManager].streamState == PLStreamStateConnected) {
        switch (sampleBufferType) {
            case RPSampleBufferTypeVideo:
                // Handle video sample buffer
                [[BroadcastManager sharedBroadcastManager] pushVideoSampleBuffer:sampleBuffer];
                break;
            case RPSampleBufferTypeAudioApp:
                // Handle audio sample buffer for app audio
                [[BroadcastManager sharedBroadcastManager] pushAudioSampleBuffer:sampleBuffer withChannelID:kPLAudioChannelApp];
                break;
            case RPSampleBufferTypeAudioMic:
                // Handle audio sample buffer for mic audio
                [[BroadcastManager sharedBroadcastManager] pushAudioSampleBuffer:sampleBuffer withChannelID:kPLAudioChannelMic];
                break;

            default:
                break;
        }
    }
}
```

### 3. 一些注意点

如果你使用 CocoaPods 管理依赖库，可能会在编译 broadcast extension target 时遇到 link error，此时请检查 Podfile 里是否为 broadcast extension target 添加相应的依赖；或者可检查以下工程设置是否更改：

![](https://raw.githubusercontent.com/pili-engineering/PLStreamingKit/master/screensnap/extension-cocoapods.png)
