## 添加采集逻辑

### 1. 添加授权

在添加实际的采集代码之前，我们先添加获取授权的代码：

``` Objective-C

void (^noPermission)(void) = ^{
    NSString *log = @"No camera permission.";
    NSLog(@"%@", log);
};

void (^requestPermission)(void) = ^{
    [AVCaptureDevice requestAccessForMediaType:AVMediaTypeVideo completionHandler:^(BOOL granted) {
        if (granted) {
            permissionGranted();
        } else {
            noPermission();
        }
    }];
};

AVAuthorizationStatus status = [AVCaptureDevice authorizationStatusForMediaType:AVMediaTypeVideo];
switch (status) {
    case AVAuthorizationStatusAuthorized:
        permissionGranted();
        break;
    case AVAuthorizationStatusNotDetermined:
        requestPermission();
        break;
    case AVAuthorizationStatusDenied:
    case AVAuthorizationStatusRestricted:
    default:
        noPermission();
        break;
}
```


### 2. 音视频采集

* 在 permissionGranted 我们加入实际的采集代码，其中有一些属性需要自行添加：

``` Objective-C
__weak typeof(self) wself = self;
void (^permissionGranted)(void) = ^{
    __strong typeof(wself) strongSelf = wself;

    NSArray *devices = [AVCaptureDevice devices];
    for (AVCaptureDevice *device in devices) {
        if ([device hasMediaType:AVMediaTypeVideo] && AVCaptureDevicePositionBack == device.position) {
            strongSelf.cameraCaptureDevice = device;
            break;
        }
    }

    if (!strongSelf.cameraCaptureDevice) {
        NSString *log = @"No back camera found.";
        NSLog(@"%@", log);
        [self logToTextView:log];
        return ;
    }

    AVCaptureSession *captureSession = [[AVCaptureSession alloc] init];
    AVCaptureDeviceInput *input = nil;
    AVCaptureVideoDataOutput *output = nil;

    input = [[AVCaptureDeviceInput alloc] initWithDevice:strongSelf.cameraCaptureDevice error:nil];
    output = [[AVCaptureVideoDataOutput alloc] init];

    strongSelf.cameraCaptureOutput = output;

    [captureSession beginConfiguration];
    captureSession.sessionPreset = AVCaptureSessionPreset640x480;

    // setup output
    output.videoSettings = @{(NSString *)kCVPixelBufferPixelFormatTypeKey: @(kCVPixelFormatType_420YpCbCr8BiPlanarFullRange)};

    dispatch_queue_t cameraQueue = dispatch_queue_create("com.pili.camera", 0);
    [output setSampleBufferDelegate:strongSelf queue:cameraQueue];

    // add input && output
    if ([captureSession canAddInput:input]) {
        [captureSession addInput:input];
    }

    if ([captureSession canAddOutput:output]) {
        [captureSession addOutput:output];
    }

    NSLog(@"%@", [AVCaptureDevice devicesWithMediaType:AVMediaTypeAudio]);

    // audio capture device
    AVCaptureDevice *microphone = [AVCaptureDevice defaultDeviceWithMediaType:AVMediaTypeAudio];
    AVCaptureDeviceInput *audioInput = [AVCaptureDeviceInput deviceInputWithDevice:microphone error:nil];
    AVCaptureAudioDataOutput *audioOutput = nil;

    if ([captureSession canAddInput:audioInput]) {
        [captureSession addInput:audioInput];
    }
    audioOutput = [[AVCaptureAudioDataOutput alloc] init];

    self.microphoneCaptureOutput = audioOutput;

    if ([captureSession canAddOutput:audioOutput]) {
        [captureSession addOutput:audioOutput];
    } else {
        NSLog(@"Couldn't add audio output");
    }

    dispatch_queue_t audioProcessingQueue = dispatch_get_global_queue(DISPATCH_QUEUE_PRIORITY_DEFAULT,0);
    [audioOutput setSampleBufferDelegate:self queue:audioProcessingQueue];

    [captureSession commitConfiguration];

    NSError *error;
    [strongSelf.cameraCaptureDevice lockForConfiguration:&error];
    strongSelf.cameraCaptureDevice.activeVideoMinFrameDuration = CMTimeMake(1.0, strongSelf.expectedSourceVideoFrameRate);
    strongSelf.cameraCaptureDevice.activeVideoMaxFrameDuration = CMTimeMake(1.0, strongSelf.expectedSourceVideoFrameRate);
    [strongSelf.cameraCaptureDevice unlockForConfiguration];

    strongSelf.cameraCaptureSession = captureSession;

    [strongSelf reorientCamera:AVCaptureVideoOrientationPortrait];

    AVCaptureVideoPreviewLayer* previewLayer;
    previewLayer =  [AVCaptureVideoPreviewLayer layerWithSession:captureSession];
    previewLayer.videoGravity = AVLayerVideoGravityResizeAspectFill;
    __weak typeof(strongSelf) wself1 = strongSelf;
    dispatch_async(dispatch_get_main_queue(), ^{
        __strong typeof(wself1) strongSelf1 = wself1;
        previewLayer.frame = strongSelf1.view.layer.bounds;
        [strongSelf1.view.layer insertSublayer:previewLayer atIndex:0];
    });

    [strongSelf.cameraCaptureSession startRunning];
};
```
